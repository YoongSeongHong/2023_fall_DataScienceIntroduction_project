{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73dce293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649cb722",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.bbc.com\"\n",
    "start_url = \"https://www.bbc.com/news/world/europe\"\n",
    "\n",
    "# 해당 페이지에서 각 기사들의 url 뽑아오는 함수\n",
    "def get_articles_urls(soup):\n",
    "    return [base_url + li.a[\"href\"] for li in soup.select(\"li.lx-stream__post-container\")], [li.find('article').find('div').find('div').find('time').find_all('span')[1].text for li in soup.select(\"li.lx-stream__post-container\")]\n",
    "\n",
    "\n",
    "# 해당 페이지 기사들의 정보 뽑아오는 코드\n",
    "def get_page_articles(driver):\n",
    "    driver_source = driver.page_source\n",
    "    soup = BeautifulSoup(driver_source, 'html.parser')\n",
    "    article_urls, article_times = get_articles_urls(soup)\n",
    "\n",
    "    article_titles = []\n",
    "    article_time_save = []\n",
    "    article_contents = []\n",
    "    article_relateds = []\n",
    "    for article_url, article_time in zip(article_urls, article_times):\n",
    "        article_title, article_content, article_related = extract_single_article_content(article_url)\n",
    "        if article_title and article_content:\n",
    "            article_titles.append(article_title)\n",
    "            article_time_save.append(article_time)\n",
    "            article_contents.append(article_content)\n",
    "            article_relateds.append(article_related)\n",
    "    return article_titles, article_time_save, article_contents, article_relateds, soup\n",
    "\n",
    "\n",
    "# 한 기사의 제목, 본문, 태그들 가져오는 함수\n",
    "def extract_single_article_content(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # 기사 제목 가져오기\n",
    "    title = soup.select_one(\"h1\")\n",
    "    if title:\n",
    "        title = title.get_text(strip=True)\n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "    # 기사 내용 가져오기\n",
    "    paragraphs = []\n",
    "    p_elements = soup.select(\"div.ssrcss-7uxr49-RichTextContainer.e5tfeyi1 > p\")\n",
    "    \n",
    "    if not p_elements: # 비어있는 경우를 확인하여 에러를 방지합니다.\n",
    "        return None, None, None\n",
    "    \n",
    "    last_p_element = p_elements[-1]\n",
    "    # div.ssrcss-7uxr49-RichTextContainer.e5tfeyi1 클래스 하위의 p 요소들을 가져오기\n",
    "    for p in p_elements:\n",
    "        # 마지막 문단의 a, i에 태그가 나올 땐 날려버려야 하는 경우가 있다.\n",
    "        if p == last_p_element:\n",
    "            # p 요소 안에 있는 모든 a와 i 태그 삭제\n",
    "            for tag in p.find_all([\"i\", \"a\"]):\n",
    "                tag.decompose()\n",
    "        # p 요소의 텍스트만 추출하여 paragraphs에 추가\n",
    "        paragraphs.append(p.text.strip())\n",
    "\n",
    "    content = \"\\n\".join(paragraphs)\n",
    "    \n",
    "    # 기사 태그 가져오기\n",
    "    tags = soup.select('div.ssrcss-1qmkvfu-TopicListWrapper.etw6iwl1 > div.ssrcss-1szabdv-StyledTagContainer.ed0g1kj1 > div.ssrcss-17ehax8-Cluster.e1ihwmse1 > ul.ssrcss-1ujonwb-ClusterItems.e1ihwmse0 > li')\n",
    "    if not tags:\n",
    "        return None, None, None\n",
    "    \n",
    "    related = ', '.join([tag.get_text() for tag in tags])\n",
    "       \n",
    "\n",
    "    return title, content, related\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6b21b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모인 기사 수: 17\n",
      "모인 기사 수: 34\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=119.0.6045.159)\nStacktrace:\n\tGetHandleVerifier [0x00007FF69BC282B2+55298]\n\t(No symbol) [0x00007FF69BB95E02]\n\t(No symbol) [0x00007FF69BA505AB]\n\t(No symbol) [0x00007FF69BA30038]\n\t(No symbol) [0x00007FF69BAB6BC7]\n\t(No symbol) [0x00007FF69BACA15F]\n\t(No symbol) [0x00007FF69BAB1E83]\n\t(No symbol) [0x00007FF69BA8670A]\n\t(No symbol) [0x00007FF69BA87964]\n\tGetHandleVerifier [0x00007FF69BFA0AAB+3694587]\n\tGetHandleVerifier [0x00007FF69BFF728E+4048862]\n\tGetHandleVerifier [0x00007FF69BFEF173+4015811]\n\tGetHandleVerifier [0x00007FF69BCC47D6+695590]\n\t(No symbol) [0x00007FF69BBA0CE8]\n\t(No symbol) [0x00007FF69BB9CF34]\n\t(No symbol) [0x00007FF69BB9D062]\n\t(No symbol) [0x00007FF69BB8D3A3]\n\tBaseThreadInitThunk [0x00007FFD2A7E257D+29]\n\tRtlUserThreadStart [0x00007FFD2BF6AA58+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, socket\u001b[38;5;241m.\u001b[39mSOCK_STREAM):\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x00000149AB401850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:487\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 487\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    488\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    489\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    490\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    491\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    492\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    497\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    498\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    499\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.bbc.comhttps', port=443): Max retries exceeded with url: //www.bbc.co.uk/usingthebbc/terms/can-i-share-things-from-the-bbc (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000149AB401850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# 변경된 페이지에 대한 정보를 크롤링하고 순환하는 데 사용\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     article_titles, article_time_save, article_contents, aricle_relateds, soup \u001b[38;5;241m=\u001b[39m get_page_articles(driver)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mget_page_articles\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article_url, article_time \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(article_urls, article_times):\n\u001b[1;32m---> 19\u001b[0m     article_title, article_content, article_related \u001b[38;5;241m=\u001b[39m extract_single_article_content(article_url)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m article_title \u001b[38;5;129;01mand\u001b[39;00m article_content:\n",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m, in \u001b[0;36mextract_single_article_content\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_single_article_content\u001b[39m(url):\n\u001b[1;32m---> 28\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     29\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:520\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.bbc.comhttps', port=443): Max retries exceeded with url: //www.bbc.co.uk/usingthebbc/terms/can-i-share-things-from-the-bbc (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000149AB401850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m         article_titles, article_time_save, article_contents, aricle_relateds, soup \u001b[38;5;241m=\u001b[39m get_page_articles(driver)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         btn\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# 웹 드라이버 종료\u001b[39;00m\n\u001b[0;32m     54\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(Command\u001b[38;5;241m.\u001b[39mCLICK_ELEMENT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:346\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    344\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    347\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=119.0.6045.159)\nStacktrace:\n\tGetHandleVerifier [0x00007FF69BC282B2+55298]\n\t(No symbol) [0x00007FF69BB95E02]\n\t(No symbol) [0x00007FF69BA505AB]\n\t(No symbol) [0x00007FF69BA30038]\n\t(No symbol) [0x00007FF69BAB6BC7]\n\t(No symbol) [0x00007FF69BACA15F]\n\t(No symbol) [0x00007FF69BAB1E83]\n\t(No symbol) [0x00007FF69BA8670A]\n\t(No symbol) [0x00007FF69BA87964]\n\tGetHandleVerifier [0x00007FF69BFA0AAB+3694587]\n\tGetHandleVerifier [0x00007FF69BFF728E+4048862]\n\tGetHandleVerifier [0x00007FF69BFEF173+4015811]\n\tGetHandleVerifier [0x00007FF69BCC47D6+695590]\n\t(No symbol) [0x00007FF69BBA0CE8]\n\t(No symbol) [0x00007FF69BB9CF34]\n\t(No symbol) [0x00007FF69BB9D062]\n\t(No symbol) [0x00007FF69BB8D3A3]\n\tBaseThreadInitThunk [0x00007FFD2A7E257D+29]\n\tRtlUserThreadStart [0x00007FFD2BF6AA58+40]\n"
     ]
    }
   ],
   "source": [
    "# 크롬 드라이버 설치, 연결\n",
    "s = Service(\"D:\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "# 브라우저 화면 크기 변경하기\n",
    "driver.maximize_window()\n",
    "\n",
    "# 웹 페이지 열기\n",
    "url = \"https://www.bbc.com/news/world/europe\"\n",
    "driver.get(url)\n",
    "\n",
    "# 데이터 프레임 초기화\n",
    "df_europe = pd.DataFrame(columns=[\"Title\", \"Time\", \"Content\", \"Related\"])\n",
    "\n",
    "# title과 content를 가져오기 위해 get_page_articles 함수 호출\n",
    "article_titles, article_time_save, article_contents, article_relateds, soup = get_page_articles(driver)\n",
    "\n",
    "body = driver.find_elements('css selector', 'body')[0]\n",
    "for i in range(17):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    \n",
    "btn = driver.find_elements('css selector', 'div > div.gel-icon.gel-icon--next')[0]\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # 데이터 프레임에 저장\n",
    "        for title, time_save, content, related in zip(article_titles, article_time_save, article_contents, article_relateds):\n",
    "            if title in df_europe:\n",
    "                continue\n",
    "            else:\n",
    "                df_europe = df_europe.append({\"Title\": title, \"Time\": time_save, \"Content\": content, \"Related\": related}, ignore_index=True)\n",
    "        \n",
    "        # 500개 까지만 모으기\n",
    "        if len(df_europe) > 500:\n",
    "                break\n",
    "\n",
    "        print('모인 기사 수: ' + str(len(df_europe)))\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        btn.click()\n",
    "\n",
    "        # 페이지를 변경한 후에도 다음 뉴스 목록을 가져올 수 있도록 변경된 페이지에 대한 soup 객체 생성\n",
    "        driver_source = driver.page_source\n",
    "        page_soup = BeautifulSoup(driver_source, 'html.parser')\n",
    "\n",
    "        # 변경된 페이지에 대한 정보를 크롤링하고 순환하는 데 사용\n",
    "        article_titles, article_time_save, article_contents, aricle_relateds, soup = get_page_articles(driver)\n",
    "\n",
    "    except:\n",
    "        btn.click()\n",
    "    \n",
    "\n",
    "# 웹 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 데이터 프레임 출력\n",
    "df_europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f22881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 기사 제거\n",
    "df_europe = df_europe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a41e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Time</th>\n",
       "      <th>Content</th>\n",
       "      <th>Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berlin on edge for Erdogan after fierce Israel...</td>\n",
       "      <td>10:30</td>\n",
       "      <td>No speeches in front of cheering crowds. No jo...</td>\n",
       "      <td>Israel-Gaza war, Germany, Recep Tayyip Erdogan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swimming rivers and faking illness to escape U...</td>\n",
       "      <td>9:30</td>\n",
       "      <td>Nearly 20,000 men have fled Ukraine since the ...</td>\n",
       "      <td>Russia-Ukraine war, Military, Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two dead and child seriously injured in road c...</td>\n",
       "      <td>7:23</td>\n",
       "      <td>Two people have died and a child has sustained...</td>\n",
       "      <td>Europe, Republic of Ireland, Waterford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain's Pedro SÃ¡nchez wins new term as PM aft...</td>\n",
       "      <td>4:30</td>\n",
       "      <td>After weeks of haggling, Socialist leader Pedr...</td>\n",
       "      <td>Europe, Spain, Pedro Sanchez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ukraine in maps: Tracking the war with Russia</td>\n",
       "      <td>2:50</td>\n",
       "      <td>Ukraine's counter-offensive has now been under...</td>\n",
       "      <td>Russia-Ukraine war, Volodymyr Zelensky, Russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Luton Airport shuttle buses join Ukraine war e...</td>\n",
       "      <td>13:48 7 Sep</td>\n",
       "      <td>Three former airport shuttle buses have been d...</td>\n",
       "      <td>Russia-Ukraine war, Russia, Ukraine, Ukrainian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>UK expected to re-join Horizon science scheme</td>\n",
       "      <td>13:39 7 Sep</td>\n",
       "      <td>The UK is expected to re-join the EU's flagshi...</td>\n",
       "      <td>Volcanoes, Iceland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Migrants bundled out of Europe lose court chal...</td>\n",
       "      <td>0:57 7 Sep</td>\n",
       "      <td>The EU's top court has dismissed a case agains...</td>\n",
       "      <td>Mark Rutte, Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Ukraine war: Romania reveals Russian drone par...</td>\n",
       "      <td>0:16 7 Sep</td>\n",
       "      <td>Romania's defence minister has said that remai...</td>\n",
       "      <td>Europe, Israel &amp; the Palestinians, Republic of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Irish government warned it risks overheating e...</td>\n",
       "      <td>22:43 6 Sep</td>\n",
       "      <td>The Irish government is at risk of overheating...</td>\n",
       "      <td>Leicester, Romania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title         Time  \\\n",
       "0    Berlin on edge for Erdogan after fierce Israel...        10:30   \n",
       "1    Swimming rivers and faking illness to escape U...         9:30   \n",
       "2    Two dead and child seriously injured in road c...         7:23   \n",
       "3    Spain's Pedro SÃ¡nchez wins new term as PM aft...         4:30   \n",
       "4        Ukraine in maps: Tracking the war with Russia         2:50   \n",
       "..                                                 ...          ...   \n",
       "324  Luton Airport shuttle buses join Ukraine war e...  13:48 7 Sep   \n",
       "325      UK expected to re-join Horizon science scheme  13:39 7 Sep   \n",
       "326  Migrants bundled out of Europe lose court chal...   0:57 7 Sep   \n",
       "327  Ukraine war: Romania reveals Russian drone par...   0:16 7 Sep   \n",
       "328  Irish government warned it risks overheating e...  22:43 6 Sep   \n",
       "\n",
       "                                               Content  \\\n",
       "0    No speeches in front of cheering crowds. No jo...   \n",
       "1    Nearly 20,000 men have fled Ukraine since the ...   \n",
       "2    Two people have died and a child has sustained...   \n",
       "3    After weeks of haggling, Socialist leader Pedr...   \n",
       "4    Ukraine's counter-offensive has now been under...   \n",
       "..                                                 ...   \n",
       "324  Three former airport shuttle buses have been d...   \n",
       "325  The UK is expected to re-join the EU's flagshi...   \n",
       "326  The EU's top court has dismissed a case agains...   \n",
       "327  Romania's defence minister has said that remai...   \n",
       "328  The Irish government is at risk of overheating...   \n",
       "\n",
       "                                               Related  \n",
       "0       Israel-Gaza war, Germany, Recep Tayyip Erdogan  \n",
       "1                Russia-Ukraine war, Military, Ukraine  \n",
       "2               Europe, Republic of Ireland, Waterford  \n",
       "3                         Europe, Spain, Pedro Sanchez  \n",
       "4    Russia-Ukraine war, Volodymyr Zelensky, Russia...  \n",
       "..                                                 ...  \n",
       "324  Russia-Ukraine war, Russia, Ukraine, Ukrainian...  \n",
       "325                                 Volcanoes, Iceland  \n",
       "326                            Mark Rutte, Netherlands  \n",
       "327  Europe, Israel & the Palestinians, Republic of...  \n",
       "328                                 Leicester, Romania  \n",
       "\n",
       "[329 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ac2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_europe.to_excel('./data/europe.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
